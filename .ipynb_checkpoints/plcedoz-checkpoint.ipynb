{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19576/19576 [00:00<00:00, 284659.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Loading Graph #########\n",
      "Reading Nodes list\n",
      "Reading Edges list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph:\n",
      "\t19576 nodes\n",
      "\t5676528 edges\n",
      "\n",
      "######### Computing/retrieving node features #########\n",
      "degree_undirected\n",
      "expecteddegree_undirected\n",
      "clusteringcoefficient\n",
      "closeness\n",
      "betweenness\n",
      "hits\n",
      "pagerank\n",
      "log10-degree_undirected\n",
      "normalized-degree_undirected\n",
      "normalized-hits\n",
      "\n",
      "Statistics for mendelian (ratio of positive examples = 0.78):\n",
      "\n",
      "Accuracy = 0.80\n",
      "Average precision = 0.90\n",
      "F1 score = 0.88\n",
      "Recall = 0.97\n",
      "AUC = 0.76\n"
     ]
    }
   ],
   "source": [
    "# This script contains everything the whole sequence of things to do\n",
    "# to get our results.\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from read_graph import read_graph\n",
    "from common.pipeline import Pipeline\n",
    "from common.feature_generators import ExpectedDegree\n",
    "from common.feature_generators import ClusteringCoefficient\n",
    "from common.feature_generators import Degree\n",
    "from common.feature_generators import ClosenessCentrality\n",
    "from common.feature_generators import BetweennessCentrality\n",
    "from common.feature_generators import HITS\n",
    "from common.feature_generators import PageRank\n",
    "from common.feature_generators import Log10Wrapper\n",
    "from common.feature_generators import NormalizeWrapper\n",
    "from validation import compute_correlations\n",
    "from prediction import get_labels, train_model, get_metrics\n",
    "\n",
    "\n",
    "# Loading PPI graph\n",
    "print(\"\\n######### Loading Graph #########\")\n",
    "Graph = read_graph(directed=False)\n",
    "print(\"Loaded graph:\\n\\t{} nodes\\n\\t{} edges\".format(\n",
    "    Graph.number_of_nodes(),\n",
    "    Graph.number_of_edges()\n",
    "))\n",
    "\n",
    "#########################\n",
    "# Computing node features\n",
    "#########################\n",
    "\n",
    "print(\"\\n######### Computing/retrieving node features #########\")\n",
    "\n",
    "# The pipeline object takes as an argument the sequence of features we want\n",
    "pipeline = Pipeline(Degree(default_dump=True, default_recomputing=False),\n",
    "                    ExpectedDegree(default_dump=True, default_recomputing=False), ClusteringCoefficient(),\n",
    "                    ClosenessCentrality(), BetweennessCentrality(), HITS(), PageRank(), Log10Wrapper(Degree())(),\n",
    "                    NormalizeWrapper(Degree())(),NormalizeWrapper(HITS())())\n",
    "features, node_names = pipeline.apply(Graph, verbose=True)\n",
    "\n",
    "#########################\n",
    "# Class prediction\n",
    "#########################\n",
    "\n",
    "print(\"\\n######### Class Prediction #########\")\n",
    "\n",
    "sources = [\"mendelian\", \"cancer\", \"drugbank\"]\n",
    "\n",
    "for source in sources:\n",
    "    labels = get_labels(node_names)\n",
    "    y_test, y_pred, y_score = train_model(features, labels, source)\n",
    "    get_metrics(y_test, y_pred, y_score, source)\n",
    "\n",
    "#########################\n",
    "# Features Correlation\n",
    "#########################\n",
    "\n",
    "print(\"\\n######### Features Correlation #########\")\n",
    "\n",
    "pvalues = compute_correlations(features, sources)\n",
    "\n",
    "# Perform gene set enrichment analysis (GSEA) on a variety of gene sets directories\n",
    "gene_sets_directories = [\n",
    "    u'Cancer_Cell_Line_Encyclopedia',\n",
    "    u'ChEA_2016',\n",
    "    u'DrugMatrix',\n",
    "    u'GeneSigDB',\n",
    "    u'KEGG_2016',\n",
    "    u'LINCS_L1000_Chem_Pert_down',\n",
    "    u'LINCS_L1000_Chem_Pert_up',\n",
    "    u'MSigDB_Computational',\n",
    "    u'MSigDB_Oncogenic_Signatures',\n",
    "    u'OMIM_Disease',\n",
    "    u'OMIM_Expanded',\n",
    "    u'PPI_Hub_Proteins',\n",
    "    u'Panther_2016',\n",
    "    u'Reactome_2016'\n",
    "]\n",
    "# enrichr = enrichr_validation(gene_query, gene_rank=None, outdir=\"validation_results\", gene_sets='KEGG_2016')\n",
    "# prerank = prerank_validation(gene_query, gene_rank, outdir=\"validation_results\", gene_sets='KEGG_2016')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
